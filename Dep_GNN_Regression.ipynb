{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tnrange, tqdm_notebook\n",
    "from tqdm import trange\n",
    "from datetime import datetime , timedelta\n",
    "from config import DefaultConfig , switch\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch as t\n",
    "import time\n",
    "import inspect\n",
    "from models import gwnet,STGCN\n",
    "from data import tem_spa_Time_series\n",
    "import torch.nn as nn\n",
    "from utils import plain_evl_result\n",
    "import fire\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dep_GNN_Regression():\n",
    "    def __init__(self,model,opt):\n",
    "        #self.opt = DefaultConfig()\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.opt = copy.deepcopy(opt)\n",
    "    def opt_update(self,**kwargs):\n",
    "        self.opt._parse(kwargs)\n",
    "        \n",
    "    def cheb_poly(self,L, Ks):\n",
    "        n = L.shape[0]\n",
    "        LL = [np.eye(n), L[:]]\n",
    "        for i in range(2, Ks):\n",
    "            LL.append(np.matmul(2 * L, LL[-1]) - LL[-2])\n",
    "        return np.asarray(LL)\n",
    "    \n",
    "    def train(self):\n",
    "#         self.opt._parse(kwargs)\n",
    "        \n",
    "        ########  get model type   ######\n",
    "        #self.get_model_type()\n",
    "        \n",
    "        ####### begin train  #####\n",
    "        self.dirs_remake(self.opt.target_foler,self.opt.name)\n",
    "        \n",
    "        self.df = pd.read_csv(self.opt.dataframe_csv)\n",
    "        file_list = self.df['device_ID'].values.tolist()\n",
    "#         if not os.path.exists(os.path.join(self.opt.target_foler,self.opt.name)):\n",
    "#             os.mkdir(os.path.join(self.opt.target_foler,self.opt.name))\n",
    "            \n",
    "#         format = lambda x : '%d' %x\n",
    "#         self.df.iloc[:,2] = self.df.iloc[:,2].map(format)\n",
    "        \n",
    "        self.evl_df = pd.DataFrame(columns=['Date','device_ID','MSE','R2_score','bias'])\n",
    "        for i in trange(self.df.shape[0], desc='progressing device number'):\n",
    "            loss_function = nn.MSELoss()\n",
    "            lr = self.opt.lr\n",
    "            \n",
    "            if not os.path.exists(os.path.join(self.opt.train_data_root,\n",
    "                                               str(self.df.iloc[i]['device_ID'])+'.csv')):\n",
    "                continue\n",
    "                \n",
    "            end = datetime.strptime(self.df.iloc[i]['time'],\"%Y-%m-%d %H:%M:%S\")\n",
    "            if str(end) == str(self.opt.start_dates):\n",
    "                flag = 0\n",
    "                \n",
    "                pm2_5 = pd.read_csv(os.path.join(self.opt.train_data_root, \n",
    "                        str(self.df.iloc[i]['device_ID'])+'.csv'),index_col=0,parse_dates=True)\n",
    "                L = np.load(os.path.join(self.opt.laplacian_folder, \n",
    "                                         str(self.df.iloc[i]['device_ID'])+'.npy'))\n",
    "                # Graph WaveNet\n",
    "                if self.opt.model == \"gwnet\":\n",
    "                    Lk = [torch.Tensor(L.astype(np.float32)).to(self.opt.device)]\n",
    "                \n",
    "                # STGCN\n",
    "                else:\n",
    "                    Lk = self.cheb_poly(L, self.opt.ks)\n",
    "                    Lk = torch.Tensor(Lk.astype(np.float32)).to(self.opt.device)\n",
    "                    \n",
    "                \n",
    "                for name, params in self.model.named_parameters():\n",
    "                    if name.find(\"end_conv_1\") != -1 or name.find(\"st_conv1\") != -1:\n",
    "                        flag = 1\n",
    "                        break\n",
    "                if flag:\n",
    "                    self.model.set_Lk(Lk)\n",
    "                else:    \n",
    "                    self.model.set_network(Lk)\n",
    "                    \n",
    "                if self.opt.load_model_path:\n",
    "                    try:\n",
    "                        for dirPath, dirNames, fileNames in os.walk(\n",
    "                                    os.path.join('save',self.opt.load_model_path)):\n",
    "                            self.model.load(os.path.join(dirPath,fileNames[0]))\n",
    "                    except:\n",
    "                        path = os.path.join('save',self.opt.load_model_path)\n",
    "                        raise ValueError(f'Not exist {path!r} model path!')\n",
    "                    \n",
    "                    self.opt.load_model_path = None\n",
    "                    \n",
    "                if self.opt.model_test:\n",
    "                    self.predict(self.model,pm2_5,end,'%Y-%m-%d',self.opt.name,i)\n",
    "                    continue\n",
    "                    \n",
    "            end_previous = str(end + timedelta(minutes = -1 ))\n",
    "            #end_previous = end_previous.strftime(\"%Y-%m-%d\")\n",
    "            self.opt_update(end_dates = end_previous)\n",
    "                \n",
    "            #pm2_5_x = pm2_5.loc[:self.opt.end_dates]\n",
    "            \n",
    "            if i == 0:\n",
    "                L = np.load(os.path.join(self.opt.laplacian_folder, \n",
    "                                             str(self.df.iloc[i]['device_ID'])+'.npy'))\n",
    "                # GraphWaveNet\n",
    "                if self.opt.model == \"gwnet\":\n",
    "                    Lk = [torch.Tensor(L.astype(np.float32)).to(self.opt.device)]\n",
    "                else:\n",
    "                    Lk = self.cheb_poly(L, self.opt.ks)\n",
    "                    Lk = torch.Tensor(Lk.astype(np.float32)).to(self.opt.device)\n",
    "                self.model.set_network(Lk)\n",
    "                \n",
    "            self.model = self.model.to(self.opt.device)\n",
    "            \n",
    "            ############# begin train ##############\n",
    "            if self.opt.model_train:\n",
    "                \n",
    "                optimizer = self.model.get_optimizer(lr, self.opt.weight_decay)\n",
    "                ###########   Create dataloader dict    ###########\n",
    "#                 dataloader_list = {}\n",
    "\n",
    "#                 for j in range(len(file_list)):\n",
    "#                     if os.path.exists(os.path.join(self.opt.train_data_root, \n",
    "#                                                        str(file_list[j])+'.csv')):\n",
    "#                         pm2_5 = pd.read_csv(os.path.join(self.opt.train_data_root, \n",
    "#                                      str(file_list[j])+'.csv'),index_col=0,parse_dates=True)\n",
    "#                     else:\n",
    "#                         continue\n",
    "#                     dataset = tem_spa_Time_series(pm2_5,self.opt.previous\n",
    "#                                 ,self.opt.start_dates,self.opt.end_dates,\n",
    "#                                       node_cnt = self.opt.input_size,)\n",
    "#                     train_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "#                                                        batch_size=self.opt.batch_size, \n",
    "#                                                        shuffle=False,num_workers = 0)\n",
    "#                     dataloader_list[j] = train_loader\n",
    "\n",
    "                total = []\n",
    "\n",
    "                for t in tnrange((self.opt.max_epoch), desc='epoch', leave=False):    \n",
    "                    total_loss = 0\n",
    "                    for k, key in enumerate(file_list):\n",
    "                        if os.path.exists(os.path.join(self.opt.train_data_root, \n",
    "                                                           str(key)+'.csv')):\n",
    "                            pm2_5 = pd.read_csv(os.path.join(self.opt.train_data_root, \n",
    "                                         str(key)+'.csv'),index_col=0,parse_dates=True)\n",
    "                        else:\n",
    "                            continue\n",
    "                        dataset = tem_spa_Time_series(pm2_5,self.opt.previous\n",
    "                                    ,self.opt.start_dates,self.opt.end_dates,\n",
    "                                          node_cnt = self.opt.input_size,)\n",
    "                        train_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                                           batch_size=self.opt.batch_size, \n",
    "                                                           shuffle=False,num_workers = 0)  \n",
    "#                     for k , (key, train_loader) in enumerate(dataloader_list.items()):\n",
    "                        L = np.load(os.path.join(self.opt.laplacian_folder, \n",
    "                                                 str(key)+'.npy'))\n",
    "                        # GraphWaveNet\n",
    "                        if self.opt.model == \"gwnet\":\n",
    "                            Lk = torch.Tensor(L.astype(np.float32)).to(self.opt.device)\n",
    "                        # STGCN\n",
    "                        else:\n",
    "                            Lk = self.cheb_poly(L, self.opt.ks)\n",
    "                            Lk = torch.Tensor(Lk.astype(np.float32)).to(self.opt.device)\n",
    "                        if not (i == 0 and t == 0 and k == 0):\n",
    "                            # Graph WaveNet\n",
    "                            self.model.set_Lk(Lk)\n",
    "\n",
    "                        if self.opt.load_model_path:\n",
    "                            try:\n",
    "                                for dirPath, dirNames, fileNames in os.walk(\n",
    "                                            os.path.join('check',self.opt.load_model_path)):\n",
    "                                    self.model.load(os.path.join(dirPath,fileNames[0]))\n",
    "                            except:\n",
    "                                path = path = os.path.join(\"check\",self.opt.load_model_path)\n",
    "                                raise ValueError(f'Not exist {path!r} model path!')\n",
    "                            \n",
    "                            self.opt.load_model_path = None\n",
    "                        for s, (datas, labels) in enumerate(train_loader):\n",
    "                            datas = datas.to(self.opt.device)\n",
    "                            labels = labels.to(self.opt.device)\n",
    "                            optimizer.zero_grad()\n",
    "                            y_pred = self.model(datas,self.opt.device)\n",
    "\n",
    "                            # Graph WaveNet loss function\n",
    "                            if self.opt.model == \"gwnet\":\n",
    "                                y_pred = y_pred[:,:,0,:].view(y_pred.size(0), -1)\n",
    "                            #single_loss = loss_function(y_pred, labels)\n",
    "\n",
    "                            #STGCN loss function\n",
    "                            else:\n",
    "                                y_pred = y_pred[:,:,:,0].view(y_pred.size(0), -1)  \n",
    "                            single_loss = loss_function(y_pred, labels)\n",
    "\n",
    "                            total_loss += single_loss.item()\n",
    "                            single_loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    if self.opt.model_save:\n",
    "                        self.model.save(self.opt.name,None)        \n",
    "\n",
    "                    total.append(total_loss)\n",
    "\n",
    "                if self.opt.visual:\n",
    "                    plt.plot(range(self.opt.max_epoch), total)\n",
    "                    plt.title(str(self.df.iloc[i]['device_ID']))\n",
    "                    plt.ylabel('Cost')\n",
    "                    plt.xlabel('Epochs')\n",
    "                    plt.show()    \n",
    "                    #scheduler.step()\n",
    "                if self.opt.model_save:\n",
    "                    self.model.save(self.opt.name,None)\n",
    "            if self.opt.model_test:\n",
    "                pm2_5 = pd.read_csv(os.path.join(self.opt.train_data_root, \n",
    "                             str(self.df.iloc[i]['device_ID'])+'.csv'),index_col=0,parse_dates=True)\n",
    "                \n",
    "                # Graph WaveNet\n",
    "                #L = torch.Tensor(L.astype(np.float32)).to(self.opt.device)\n",
    "                self.predict(self.model,pm2_5,end,'%Y-%m-%d',self.opt.name,i)\n",
    "                \n",
    "            self.opt.start_dates = str(end)\n",
    "            \n",
    "        if self.opt.model_test:\n",
    "            self.evl_df.to_csv(os.path.join\n",
    "                   (self.opt.target_foler,self.opt.name,\"evl_df.csv\"),index=0)\n",
    "            plain_evl_result(self.evl_df,self.opt.target_foler,self.opt.name,self.opt.at_n)        \n",
    "            \n",
    "    def dirs_remake(self,target_foler,model):\n",
    "        if os.path.exists(os.path.join(target_foler,model)):   #如果存在資料夾 , 刪除並重建一個\n",
    "            shutil.rmtree(os.path.join(target_foler,model))\n",
    "            os.mkdir(os.path.join(target_foler,model))\n",
    "        else:\n",
    "            os.mkdir(os.path.join(target_foler,model))\n",
    "            \n",
    "    def data_output(self,Model,pm2_5,date,day_format,index):\n",
    "        test = pm2_5[date.strftime(day_format)]\n",
    "        test_start_dates = str(test.index[0])\n",
    "        test_end_dates = str(test.index[test.shape[0]-1])\n",
    "        L = np.load(os.path.join(self.opt.laplacian_folder, \n",
    "                                 str(self.df.iloc[index]['device_ID'])+'.npy'))\n",
    "        if self.opt.model == \"gwnet\":\n",
    "            Lk = [torch.Tensor(L.astype(np.float32)).to(self.opt.device)]\n",
    "        else:\n",
    "            Lk = self.cheb_poly(L, self.opt.ks)\n",
    "            Lk = torch.Tensor(Lk.astype(np.float32)).to(self.opt.device)\n",
    "        Model.set_Lk(Lk)\n",
    "        dataset = tem_spa_Time_series(pm2_5,self.opt.previous,\n",
    "                                  test_start_dates,test_end_dates,node_cnt = self.opt.input_size,\n",
    "                                      )\n",
    "        test_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                           batch_size=self.opt.batch_size, \n",
    "                                           shuffle=False)\n",
    "        with torch.no_grad():\n",
    "            for k ,(datas, labels) in enumerate(test_loader): \n",
    "                Model = Model.to(self.opt.device)\n",
    "                datas = datas.to(self.opt.device)\n",
    "                outputs = Model(datas,self.opt.device)\n",
    "                \n",
    "                # GraphWaveNet Output\n",
    "                if self.opt.model == \"gwnet\":\n",
    "                    outputs = outputs[:,:,0,:].view(outputs.size(0), -1)\n",
    "                # STGCN Output\n",
    "                else:\n",
    "                    outputs = outputs[:,:,:,0].view(outputs.size(0), -1)  \n",
    "                if k == 0:\n",
    "                    result = outputs.cpu().numpy()\n",
    "                    labs = labels.cpu().numpy()\n",
    "                else:\n",
    "                    tmp = outputs.cpu().numpy()\n",
    "                    tmp_labs = labels.cpu().numpy()\n",
    "                    #tmp_labs = tmp_labs.reshape(-1, 1)\n",
    "                    result = np.concatenate([result, tmp], axis=0)\n",
    "                    labs = np.concatenate([labs, tmp_labs], axis=0)\n",
    "        return labs , result\n",
    "    \n",
    "    def predict(self,Model,pm2_5,date,day_format,target,index):\n",
    "    #df_1 = pd.DataFrame(columns=['Date','MSE','Score'])\n",
    "    #for date in dates:\n",
    "    labs , result = self.data_output(Model,pm2_5,date,day_format,index)\n",
    "\n",
    "    self.evl_df = self.evl_df.append({\"Date\":date.strftime(day_format),\n",
    "                        \"device_ID\":self.df.iloc[index]['device_ID'],\n",
    "                        \"MSE\":mean_squared_error(labs, result)\n",
    "                            ,\"R2_score\":r2_score(labs, result),\n",
    "                             \"bias\": self.df.iloc[index]['bias']},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(**kwargs):\n",
    "    opt = DefaultConfig()\n",
    "    opt._parse(kwargs)\n",
    "    model_kwargs = {}\n",
    "    for case in switch(opt.model):\n",
    "        if case('gwnet'):\n",
    "            for k in inspect.getfullargspec(gwnet).args:\n",
    "                if hasattr(opt, k):\n",
    "                    model_kwargs[k] = getattr(opt,k)\n",
    "            model = gwnet(**model_kwargs)\n",
    "            break\n",
    "        if case ('STGCN'):\n",
    "            for k in inspect.getfullargspec(STGCN).args:\n",
    "                if hasattr(opt, k):\n",
    "                    model_kwargs[k] = getattr(opt,k)\n",
    "            model = STGCN(**model_kwargs)\n",
    "            break  \n",
    "\n",
    "        if case():\n",
    "            raise ValueError(f'Invalid inputs model type ,must be {\"gwnet\"!r} or {\"STGCN\"!r} !')\n",
    "    Regression = Dep_GNN_Regression(model,opt)\n",
    "    Regression.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STGCN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(target_foler='result',name = \"Dep_STGCN_v1\",use_gpu = True\n",
    "      ,max_epoch = 10 ,sequence_length = 30,model_save = True,visual = False\n",
    "      ,model_test = True,previous= 30 ,batch_size = 64 ,input_size = 6\n",
    "      ,load_model_path=None,start_dates = '2018-01-01 01:30:00'\n",
    "       ,model=\"STGCN\",ks = 7, kt = 3, bs = [1, 4, 8, 8, 16, 32], sequence_length = 30, \n",
    "               nun_nodes = 6,dropout = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphWaveNet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(target_foler='result', name = 'Dep_GraphWaveNet_v1' ,use_gpu = True\n",
    "                  ,max_epoch = 10 ,sequence_length = 30,model_save = False ,visual = False\n",
    "                  ,model_test = True,previous=30,batch_size = 64 ,input_size = 6\n",
    "                  ,load_model_path=False,start_dates = '2018-01-01 01:30:00',out_feature = 1,\n",
    "                 model=\"gwnet\", num_nodes=6, dropout=0.0, gcn_bool=True, addaptadj=True, \n",
    "               aptinit=None, in_dim=1, out_dim=1,sequence_length=30, residual_channels=4, \n",
    "               dilation_channels=8, skip_channels =8, end_channels=16,kernel_size=3,blocks=4,\n",
    "              layers=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
