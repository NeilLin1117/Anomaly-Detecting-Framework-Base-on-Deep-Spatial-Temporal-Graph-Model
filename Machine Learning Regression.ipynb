{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Linear Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "#from sklearn.externals import joblib\n",
    "from tqdm import tqdm ,trange\n",
    "from tqdm.notebook import tnrange, tqdm_notebook\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from datetime import datetime , timedelta\n",
    "#from sklearn.externals import joblib\n",
    "from config import DefaultConfig , switch\n",
    "import torch\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.linear_model import Lasso , Ridge\n",
    "from data import tem_spa_Time_series\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from utils import plain_evl_result\n",
    "import fire\n",
    "import inspect\n",
    "import joblib"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fire'",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fd3e28104559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplain_evl_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fire'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class Machine_learning_Regression():\n",
    "    \n",
    "    def __init__(self,pipe_lr,opt):\n",
    "        self.pipe_lr = pipe_lr\n",
    "        \n",
    "        self.opt = opt\n",
    "    \n",
    "    def opt_update(self,**kwargs):\n",
    "        \n",
    "        self.opt._parse(kwargs)\n",
    "        \n",
    "    def time_rolling(self,train_date,dataframe,start_date,end_date,previous):\n",
    "        for i in range(self.opt.input_size):\n",
    "            tmp = dataframe.loc[train_date:,:]\n",
    "            tmp = tmp.iloc[:,i].to_frame()\n",
    "            if i == 0:\n",
    "                \n",
    "                time_previous=np.arange(previous)\n",
    "                index = np.add.outer(time_previous,np.arange(tmp.shape[0]-previous)).transpose().reshape(-1)\n",
    "                res = tmp.iloc[index]\n",
    "                new = res.values.reshape(-1,previous)\n",
    "            \n",
    "            else:\n",
    "                #tmp = dataframe.loc[self.train_date:,col].to_frame()\n",
    "                \n",
    "                time_previous=np.arange(previous)\n",
    "                index = np.add.outer(time_previous,np.arange(tmp.shape[0]-previous)).transpose().reshape(-1)\n",
    "                res = tmp.iloc[index]\n",
    "                tmp_new = res.values.reshape(-1,previous)\n",
    "                new = np.concatenate((new,tmp_new),axis=1)\n",
    "        return new\n",
    "    \n",
    "    def train(self):\n",
    "#         self.opt._parse(kwargs)\n",
    "#         self.get_model_type()\n",
    "        self.dirs_remake(self.opt.target_foler,self.opt.name)\n",
    "        #self.dirs_remake(self.opt.target_foler,self.opt.model_by_day)\n",
    "        \n",
    "        self.df = pd.read_csv(self.opt.dataframe_csv) \n",
    "#         self.df.iloc[:,2] = self.df.iloc[:,2].map(format)\n",
    "#         format = lambda x : '%d' %x\n",
    "  \n",
    "        self.evl_df = pd.DataFrame(columns=['Date','device_ID','MSE','R2_score','bias'])\n",
    "        for i in tnrange(self.df.shape[0], desc='progressing device number'):\n",
    "        #for i in range(self.df.shape[0]):\n",
    "           \n",
    "            #df_1 = pd.DataFrame(columns=['Date','MSE','Score'])\n",
    "            if os.path.exists(os.path.join(self.opt.train_data_root, str(self.df.iloc[i]['device_ID'])+'.csv')):\n",
    "                pm2_5 = pd.read_csv(os.path.join(self.opt.train_data_root, str(self.df.iloc[i]\n",
    "                                   ['device_ID'])+'.csv'),index_col=0,parse_dates=True)\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            if self.opt.load_model_path:\n",
    "                try:\n",
    "                    for dirPath, dirNames, fileNames in os.walk(\n",
    "                                os.path.join('save',self.opt.load_model_path,str(self.df.iloc[i]['device_ID']))):\n",
    "                        self.load(os.path.join(dirPath,fileNames[0]))\n",
    "                        \n",
    "                except:\n",
    "                    path = os.path.join('save',self.opt.load_model_path,str(self.df.iloc[i]['device_ID']))\n",
    "                    raise ValueError(f'Not exist {path!r} model path!')\n",
    "                    \n",
    "            end = datetime.strptime(self.df.iloc[i]['time'][:-3],\"%Y-%m-%d %H:%M\")\n",
    "            end_previous = str(end + timedelta(minutes = -1 ))\n",
    "            \n",
    "            self.opt_update(end_dates = end_previous)\n",
    "            select_pm_2_5_x = pm2_5.loc[:self.opt.end_dates]\n",
    "\n",
    "            start = datetime.strptime(self.opt.start_dates,\"%Y-%m-%d %H:%M:%S\")\n",
    "            train_date = str(start + timedelta(minutes= (-self.opt.previous) ))\n",
    "            new_data = self.time_rolling(train_date,\n",
    "                    select_pm_2_5_x,self.opt.start_dates,self.opt.end_dates,self.opt.previous)\n",
    "           \n",
    "            labels = select_pm_2_5_x.loc[self.opt.start_dates:]\n",
    "            labels = labels.loc[:,['label']].values\n",
    "            \n",
    "            if self.opt.model_train:\n",
    "                self.pipe_lr.fit(new_data, labels.ravel())\n",
    "                if self.opt.model_save:\n",
    "                    self.save(self.opt.name,str(self.df.iloc[i]['device_ID']))\n",
    "            #end = str(end)[:-3]\n",
    "            if self.opt.model_test:\n",
    "                self.predict(pm2_5,end,'%Y-%m-%d',self.opt.name,i)\n",
    "        if self.opt.model_test:\n",
    "            self.evl_df.to_csv(os.path.join\n",
    "                   (self.opt.target_foler,self.opt.name,\"evl_df.csv\"),index=0)\n",
    "            plain_evl_result(self.evl_df,self.opt.target_foler,self.opt.name,self.opt.at_n)\n",
    "        \n",
    "    def load(self,path):\n",
    "        self.pipe_lr = joblib.load(path)\n",
    "        \n",
    "                    \n",
    "    def dirs_remake(self,target_foler,model):\n",
    "        if os.path.exists(os.path.join(target_foler,model)):   #如果存在資料夾 , 刪除並重建一個\n",
    "            shutil.rmtree(os.path.join(target_foler,model))\n",
    "            os.mkdir(os.path.join(target_foler,model))\n",
    "        else:\n",
    "            os.mkdir(os.path.join(target_foler,model))\n",
    "            \n",
    "    def predict(self,pm2_5,date,day_format,target,index):\n",
    "        #df_1 = pd.DataFrame(columns=['Date','MSE','Score'])\n",
    "        #for date in dates: \n",
    "        test_y , pm2_5_y_pred = self.data_output(pm2_5,date,day_format)\n",
    "        if True in np.isnan(pm2_5_y_pred):\n",
    "            pm2_5_y_pred = np.nan_to_num(pm2_5_y_pred)\n",
    "        self.evl_df = self.evl_df.append({\"Date\":date.strftime(day_format),\n",
    "                              \"device_ID\":self.df.iloc[index]['device_ID'],\n",
    "                              \"MSE\":mean_squared_error(test_y, pm2_5_y_pred)\n",
    "                        ,\"R2_score\":r2_score(test_y, pm2_5_y_pred),\n",
    "                      \"bias\": self.df.iloc[index]['bias']},ignore_index=True)\n",
    "    #df_1.to_csv(\"Linear_pm_2_5/\"+str(df.iloc[i]['deviceId']) + \".csv\",index=0)\n",
    "        #df_1.to_csv(os.path.join(self.opt.target_foler,target,str(self.df.iloc[index]['device_ID']) + \".csv\"),index=0)\n",
    "    \n",
    "    def data_output(self,pm2_5,date,day_format):\n",
    "        #print(date.strftime(day_format))\n",
    "        test = pm2_5[date.strftime(day_format)]\n",
    "        test_start_dates = str(test.index[0])\n",
    "        test_end_dates = str(test.index[test.shape[0]-1])\n",
    "        start = datetime.strptime(test_start_dates[:-3],\"%Y-%m-%d %H:%M\")\n",
    "        test_train_date = str(start + timedelta(minutes= (-self.opt.previous) ))\n",
    "        test = pm2_5.loc[:test_end_dates]\n",
    "        new_data = self.time_rolling(test_train_date,test,test_start_dates,test_end_dates,self.opt.previous)\n",
    "        #test = test.loc[test_start_dates:]\n",
    "        labels = test.loc[test_start_dates:]\n",
    "        labels = labels.loc[:,['label']].values\n",
    "        pm2_5_y_pred = self.pipe_lr.predict(new_data)   \n",
    "        pm2_5_y_pred = pm2_5_y_pred.reshape(-1, 1)\n",
    "        labels = labels.reshape(-1, 1)\n",
    "        return labels , pm2_5_y_pred\n",
    "    \n",
    "    def save(self,save_path,name, device):\n",
    "        \n",
    "        if not os.path.exists(os.path.join('.','save')):\n",
    "            os.mkdir(os.path.join('.','save'))\n",
    "        #檢查checkpoints目錄下是否有模型的資料夾存在\n",
    "        if not os.path.exists(os.path.join(save_path,name)):\n",
    "            os.mkdir(os.path.join('save',name))\n",
    "        if not os.path.exists(os.path.join('save',name,device)):\n",
    "            os.mkdir(os.path.join('save',name,device))\n",
    "        prefix = './save/' + name + '/' + device + '/'\n",
    "            \n",
    "        #names = time.strftime(prefix + '%Y_%m%d_%H:%M:%S.pkl')\n",
    "        names = (prefix +self.opt.name+'.pkl')\n",
    "        joblib.dump(self.pipe_lr, names)\n",
    "        return names"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def regression(**kwargs):\r\n",
    "    opt = DefaultConfig()\r\n",
    "    opt._parse(kwargs)\r\n",
    "    model_kwargs = {}\r\n",
    "    for case in switch(opt.model):\r\n",
    "        if case('Lasso'):\r\n",
    "            for k in inspect.getfullargspec(Lasso).args:\r\n",
    "                if hasattr(opt, k):\r\n",
    "                    model_kwargs[k] = getattr(opt,k)\r\n",
    "            pipe_lr = make_pipeline(Lasso(**model_kwargs))\r\n",
    "            break\r\n",
    "        if case ('Ridge'):\r\n",
    "            for k in inspect.getfullargspec(Ridge).args:\r\n",
    "                if hasattr(opt, k):\r\n",
    "                    model_kwargs[k] = getattr(opt,k)\r\n",
    "            pipe_lr = make_pipeline(Ridge(**model_kwargs))\r\n",
    "            break\r\n",
    "\r\n",
    "        if case ('RandomForest'):\r\n",
    "            for k in inspect.getfullargspec(RandomForestRegressor).args:\r\n",
    "                if hasattr(opt, k):\r\n",
    "                    model_kwargs[k] = getattr(opt,k)\r\n",
    "            pipe_lr = make_pipeline(RandomForestRegressor(**model_kwargs))\r\n",
    "            break\r\n",
    "        if case():\r\n",
    "            raise ValueError(f'Invalid inputs model type ,must be'\r\n",
    "                                '{\"Lasso\"!r} or {\"Ridge\"!r} or {\"RandomForest\"!r} !')\r\n",
    "            \r\n",
    "    Regression = Machine_learning_Regression(pipe_lr,opt)\r\n",
    "    Regression.train()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "regression(target_foler='output',name = \"Random_Forest_v1\",model_save = False,\r\n",
    "           input_size = 6,previous = 30,sequence_length = 30,load_model_path=None,\r\n",
    "           start_dates = '2018-01-01 01:30:00',model=\"RandomForest\",n_estimators=25, \r\n",
    "           criterion='mse', random_state=3,n_jobs=-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lasso Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "regression(target_foler='output',name = \"Lasso_v1\",model_save = False,\r\n",
    "           input_size = 6,previous = 30,sequence_length = 30,load_model_path=None,\r\n",
    "           start_dates = '2018-01-01 01:30:00',model=\"Lasso\",alpha=1.0,random_state = 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ridge Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "regression(target_foler='output',name = \"Ridge_v1\",model_save = False,\r\n",
    "           input_size = 6,previous = 30,sequence_length = 30,load_model_path=None,\r\n",
    "           start_dates = '2018-01-01 01:30:00',model=\"Ridge\",alpha=1.0,random_state = 3)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}